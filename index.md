![Image](/assets/dp.JPG){:height="50%" width="50%"}

## About Me
------

I am a graduate student in the Robotics Institute at Carnegie Mellon University, pursuing MS in Robotic Systems Development (MRSD). I work on autonomous navigation for quadrotors and ground vehicles, mainly on the control and motion planning side. I am interested in solving these problems using the conventional as well as learning based approaches. I have also worked on LIDAR perception algorithms and deep reinforcement learning for quadrotor navigation. Prior to this, I completed my Bachelor of Technology in Mechanical Engineering from National Institute of Technology Karnataka, Surathkal, India. 

## Projects
------

* **FlySense - Augmented Reality based assistive technology For safe aerial navigation**  
&nbsp;&nbsp;*MRSD capstone project, August'17-May'18, Carnegie Mellon University*

An Augmented Reality (AR) based assistive system that provides complete and enhanced situational awareness through real time visual and audio feedback and enables pilots to navigate safely. FlySense offers a high level of assistance through mapping of surrounding obstacles and low-level autonomy to override bad decisions by the pilot. The entire system is tested in flight using a DJI M100 quadcopter equipped with a Velodyne LIDAR and camera, streaming the required information real time to the Epson BT-300 AR headset worn by the pilot. The obstacle information is projected as a Bird's Eye View, the relevant aerial data for pilot's reference added as a Head's Up Display and finally merged with the First Person View video coming from the onboard camera to complete the FlySense interface. Wearing the AR headset, the pilot is made to control the DJI M-100 quadcopter using the RC controller by only relying on the interface and no direct line of sight with the vehicle.     
[[report]](/assets/TeamC_FinalReport.pdf), [[poster]](/assets/TeamC_Poster.pdf), [[video]](https://youtu.be/h-aslf8awWk), [[website]](https://mrsdprojects.ri.cmu.edu/2017teamc/), [[code]](https://github.com/hks95/flysense_sensing/tree/master).   
```ruby
def hello
   puts "Hello world!"
end
```


2. **Trajectory tracking control of a quadcopter using cascaded linear and nonlinear techniques**

3. **Learning control policies for quadcopter navigation with battery constraints**

4. **Field scale autonomy for vineyards**

5. **Autonomous navigation stack for a KUKA youBot for a controlled indoor environment**

6. **Data processing for real world user drive cycle generation and fuel economy simulations**

## Useful links

Email: **hsuresh@andrew.cmu.edu** 

Linkedin: **https://www.linkedin.com/in/harikrishnan-suresh**

Github: **hks95**

